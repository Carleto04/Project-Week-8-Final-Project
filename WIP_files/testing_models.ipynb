{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment       author  \\\n",
       "0  1956967341       empty   xoshayzers   \n",
       "1  1956967666     sadness    wannamama   \n",
       "2  1956967696     sadness    coolfunky   \n",
       "3  1956967789  enthusiasm  czareaquino   \n",
       "4  1956968416     neutral    xkilljoyx   \n",
       "\n",
       "                                             content  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                Funeral ceremony...gloomy friday...  \n",
       "3               wants to hang out with friends SOON!  \n",
       "4  @dannycastillo We want to trade with someone w...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset to train models\n",
    "emotions = pd.read_csv('../Data/text_emotion.csv')\n",
    "\n",
    "# create a security copy\n",
    "emotions_copy = emotions.copy()\n",
    "\n",
    "# display the first rows to verify the dataframe status\n",
    "emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     8638\n",
       "2     8459\n",
       "11    5209\n",
       "3     5165\n",
       "12    3842\n",
       "7     2187\n",
       "9     1776\n",
       "8     1526\n",
       "0     1323\n",
       "4      827\n",
       "10     759\n",
       "5      179\n",
       "1      110\n",
       "Name: sent_num, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign each sentiment to a numeric value\n",
    "vals_to_replace = {'anger': 1, 'worry': 2, 'love': 12, 'hate': 0, 'sadness': 3, 'empty': 4, 'boredom': 5, 'neutral': 6,\n",
    "                   'surprise': 7, 'relief': 8, 'fun': 9, 'enthusiasm': 10, 'happiness': 11}\n",
    "emotions['sent_num'] = emotions.sentiment.map(vals_to_replace)\n",
    "emotions['sent_num'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopword_del(sentence):\n",
    "    stopwords_list = stopwords.words(\"english\")\n",
    "    word_tokens_test = word_tokenize(sentence.lower())\n",
    "    tokens_without_sw = [word for word in word_tokens_test if not word in stopwords_list]\n",
    "    str1 = ' '.join(tokens_without_sw)\n",
    "    return str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliar function to remove a pattern defined by a regular expression \n",
    "def remove_by_regex(tweet, regexp):\n",
    "        return re.sub(regexp, '', tweet)\n",
    "\n",
    "# 3 specific cleaning functions to remove numbers, url's and special characters\n",
    "def remove_numbers(tweet):\n",
    "    return remove_by_regex(tweet, re.compile(r\"[1234567890]\"))\n",
    "\n",
    "def remove_url(tweet):\n",
    "    return remove_by_regex(tweet, re.compile(r\"http.?://[^\\s]+[\\s]?\"))\n",
    "\n",
    "def remove_special_char(tweet):\n",
    "    return re.sub(r\"[^a-zA-Z0-9 ]\", \"\", tweet) #add space placeholder\n",
    "\n",
    "# general cleaning function to do it all at once\n",
    "def clean_up(tweet):\n",
    "    tweet = remove_numbers(tweet)\n",
    "    tweet = remove_url(tweet)\n",
    "    tweet = remove_special_char(tweet)\n",
    "    return tweet.lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaa</th>\n",
       "      <th>aaaaaaaa</th>\n",
       "      <th>aaaaaaaaaaa</th>\n",
       "      <th>aaaaaaaaaahhhhhhhh</th>\n",
       "      <th>aaaaaaaaaamazing</th>\n",
       "      <th>aaaaaaaafternoon</th>\n",
       "      <th>aaaaaaaahhhhhhhh</th>\n",
       "      <th>...</th>\n",
       "      <th>zyrtec</th>\n",
       "      <th>zzerbe</th>\n",
       "      <th>zzwhitejd</th>\n",
       "      <th>zzybug</th>\n",
       "      <th>zzz</th>\n",
       "      <th>zzzz</th>\n",
       "      <th>zzzzy</th>\n",
       "      <th>zzzzz</th>\n",
       "      <th>zzzzzzz</th>\n",
       "      <th>zzzzzzzzzzzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47433 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aaa  aaaa  aaaaa  aaaaaaaa  aaaaaaaaaaa  aaaaaaaaaahhhhhhhh  \\\n",
       "0  0.0  0.0   0.0    0.0       0.0          0.0                 0.0   \n",
       "1  0.0  0.0   0.0    0.0       0.0          0.0                 0.0   \n",
       "2  0.0  0.0   0.0    0.0       0.0          0.0                 0.0   \n",
       "3  0.0  0.0   0.0    0.0       0.0          0.0                 0.0   \n",
       "4  0.0  0.0   0.0    0.0       0.0          0.0                 0.0   \n",
       "\n",
       "   aaaaaaaaaamazing  aaaaaaaafternoon  aaaaaaaahhhhhhhh  ...  zyrtec  zzerbe  \\\n",
       "0               0.0               0.0               0.0  ...     0.0     0.0   \n",
       "1               0.0               0.0               0.0  ...     0.0     0.0   \n",
       "2               0.0               0.0               0.0  ...     0.0     0.0   \n",
       "3               0.0               0.0               0.0  ...     0.0     0.0   \n",
       "4               0.0               0.0               0.0  ...     0.0     0.0   \n",
       "\n",
       "   zzwhitejd  zzybug  zzz  zzzz  zzzzy  zzzzz  zzzzzzz  zzzzzzzzzzzzzzz  \n",
       "0        0.0     0.0  0.0   0.0    0.0    0.0      0.0              0.0  \n",
       "1        0.0     0.0  0.0   0.0    0.0    0.0      0.0              0.0  \n",
       "2        0.0     0.0  0.0   0.0    0.0    0.0      0.0              0.0  \n",
       "3        0.0     0.0  0.0   0.0    0.0    0.0      0.0              0.0  \n",
       "4        0.0     0.0  0.0   0.0    0.0    0.0      0.0              0.0  \n",
       "\n",
       "[5 rows x 47433 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stopwords\n",
    "emotions['content'] = emotions['content'].apply(stopword_del)\n",
    "\n",
    "#apply previously defined functions all at once\n",
    "emotions[\"content\"] = emotions[\"content\"].apply(clean_up)\n",
    "\n",
    "#stem the words in the sentences and delete too-large-whitespaces\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "emotions[\"content_stemmed\"] = emotions[\"content\"].apply(stemmer.stem)\n",
    "emotions[\"content_stemmed\"] = [' '.join(x.split()) for x in emotions[\"content\"]]\n",
    "\n",
    "#convert the words in sentences to a new dataframe of vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "content_vect = vectorizer.fit_transform(emotions.content_stemmed)\n",
    "vector_df = pd.DataFrame.sparse.from_spmatrix(content_vect.tocoo(), columns = vectorizer.get_feature_names())\n",
    "vector_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Series' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-517e604f7a94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvector_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'Series' object is not callable"
     ]
    }
   ],
   "source": [
    "vector_df.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaa</th>\n",
       "      <th>aaaaaaaa</th>\n",
       "      <th>aaaaaaaaaaa</th>\n",
       "      <th>aaaaaaaaaahhhhhhhh</th>\n",
       "      <th>aaaaaaaaaamazing</th>\n",
       "      <th>aaaaaaaafternoon</th>\n",
       "      <th>aaaaaaaahhhhhhhh</th>\n",
       "      <th>...</th>\n",
       "      <th>zzerbe</th>\n",
       "      <th>zzwhitejd</th>\n",
       "      <th>zzybug</th>\n",
       "      <th>zzz</th>\n",
       "      <th>zzzz</th>\n",
       "      <th>zzzzy</th>\n",
       "      <th>zzzzz</th>\n",
       "      <th>zzzzzzz</th>\n",
       "      <th>zzzzzzzzzzzzzzz</th>\n",
       "      <th>sent_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aaa  aaaa  aaaaa  aaaaaaaa  aaaaaaaaaaa  aaaaaaaaaahhhhhhhh  \\\n",
       "0  0.0  0.0   0.0    0.0       0.0          0.0                 0.0   \n",
       "1  0.0  0.0   0.0    0.0       0.0          0.0                 0.0   \n",
       "2  0.0  0.0   0.0    0.0       0.0          0.0                 0.0   \n",
       "3  0.0  0.0   0.0    0.0       0.0          0.0                 0.0   \n",
       "4  0.0  0.0   0.0    0.0       0.0          0.0                 0.0   \n",
       "\n",
       "   aaaaaaaaaamazing  aaaaaaaafternoon  aaaaaaaahhhhhhhh  ...  zzerbe  \\\n",
       "0               0.0               0.0               0.0  ...     0.0   \n",
       "1               0.0               0.0               0.0  ...     0.0   \n",
       "2               0.0               0.0               0.0  ...     0.0   \n",
       "3               0.0               0.0               0.0  ...     0.0   \n",
       "4               0.0               0.0               0.0  ...     0.0   \n",
       "\n",
       "   zzwhitejd  zzybug  zzz  zzzz  zzzzy  zzzzz  zzzzzzz  zzzzzzzzzzzzzzz  \\\n",
       "0        0.0     0.0  0.0   0.0    0.0    0.0      0.0              0.0   \n",
       "1        0.0     0.0  0.0   0.0    0.0    0.0      0.0              0.0   \n",
       "2        0.0     0.0  0.0   0.0    0.0    0.0      0.0              0.0   \n",
       "3        0.0     0.0  0.0   0.0    0.0    0.0      0.0              0.0   \n",
       "4        0.0     0.0  0.0   0.0    0.0    0.0      0.0              0.0   \n",
       "\n",
       "   sent_num  \n",
       "0         4  \n",
       "1         3  \n",
       "2         3  \n",
       "3        10  \n",
       "4         6  \n",
       "\n",
       "[5 rows x 47434 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add label to the vectorized dataframe\n",
    "vector_df['sent_num'] = emotions['sent_num']\n",
    "vector_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test sets to apply in models\n",
    "train_set, test_set = train_test_split(vector_df, test_size=0.3)\n",
    "train_X = train_set.drop(columns='sent_num')\n",
    "train_y = train_set['sent_num']\n",
    "test_X = test_set.drop(columns='sent_num')\n",
    "test_y = test_set['sent_num']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, multi_class='multinomial')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LogR = LogisticRegression(max_iter = 1000, multi_class=\"multinomial\")\n",
    "model_LogR.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5717142857142857"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LogR.score(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SuperVectorMachine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tolay\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(multi_class='crammer_singer')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "LSVC = LinearSVC(multi_class='crammer_singer')\n",
    "LSVC.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8930357142857143"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSVC.score(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30833333333333335"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSVC.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8426428571428571"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(max_depth=200)\n",
    "rfc.fit(train_X, train_y)\n",
    "predictions_rfc = rfc.predict(train_X)\n",
    "accuracy_score(train_y, predictions_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3353333333333333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_rfc_test = rfc.predict(test_X)\n",
    "accuracy_score(test_y, predictions_rfc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
